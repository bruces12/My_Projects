{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we will need some of these packages at varoius points\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "This code processes images of handwritten letters and creates a CNN to classify these images\n",
    "We include every lower case letter as well as select upper case letters\n",
    "In addition the model will be trained to recognize various types of images that are not letters such as empty images, and images that only have straight lines\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def model(features,labels,mode):\n",
    "    #this function defines a custom model\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 100, 100, 1])#100x100\n",
    "    #perform convolutions with relu at the end of each convolution and some dropout, then pooling\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)#50x50\n",
    "    dropoutp1=tf.layers.dropout(inputs=pool1,rate=0.05,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=dropoutp1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)#25x25\n",
    "    dropoutp2=tf.layers.dropout(inputs=pool2,rate=0.06,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=dropoutp2,\n",
    "      filters=24,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "      \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[5,5], strides=5)#5x5\n",
    "    dropoutp3=tf.layers.dropout(inputs=pool3,rate=0.07,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "      inputs=dropoutp3,\n",
    "      filters=16,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    \n",
    "    #flatten the images which are 5x5 but is also 16 units deep (because our last convolution layer had 16 filters) to give total length of 3*3*81\n",
    "    pool4_flat=tf.reshape(conv4, [-1,16*25])\n",
    "    #define our dense layer\n",
    "    dense=tf.layers.dense(inputs=pool4_flat,units=256,activation=tf.nn.elu)\n",
    "    #do one final dropout, this time much more dropout than we saw earlier\n",
    "    dropout=tf.layers.dropout(inputs=dense,rate=0.4,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    logits=tf.layers.dense(inputs=dropout,units=3)\n",
    "    \n",
    "    predictions={\n",
    "      \"classes\":tf.argmax(input=logits,axis=1),\n",
    "      \"probabilities\":tf.nn.softmax(logits,name=\"softmax_tensor\")\n",
    "      }\n",
    "    \n",
    "    #perform the operations appropriate for the mode we are in\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)\n",
    "    \n",
    "    labels_one_hot=tf.one_hot(indices=tf.cast(labels, tf.int32), depth=3)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels_one_hot, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer=tf.train.GradientDescentOptimizer(learning_rate=.01)\n",
    "        train_op = optimizer.minimize(\n",
    "          loss=loss,\n",
    "          global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "def get_feature_dict(images,labes):\n",
    "    #simply makes a dictionary mapping input (x's) to correct output (y's)\n",
    "    return {\"x\":images,\"y\":labels}\n",
    "        \n",
    "def train(train_data,train_labels,eval_data,eval_labels,model_folder,batch_size,steps):\n",
    "    #we take a a folder with images to train on\n",
    "    #a folder to evaluate our model with\n",
    "    #and a folder to save our model in, if this folder already has a model it will attempt to restore that model\n",
    "    #Raises an error if the model folder contains a model that does not match the format defined in our model function\n",
    "\n",
    "    classifier= tf.estimator.Estimator(model_fn = model, model_dir = model_folder)\n",
    "    #defined using our model function above\n",
    "    #tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    #logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)\n",
    "    #we can see the above log results for every 50 steps during training\n",
    "    \n",
    "    #Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=steps)\n",
    "    #hooks=[logging_hook])\n",
    "    \n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "    \n",
    "def predict(image,model_folder):\n",
    "    #this model takes an image and a folder with a trained model and makes a prediction using the model\n",
    "    classifier= tf.estimator.Estimator(model_fn = model, model_dir = model_folder)\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "    # predict with the model and print results\n",
    "    pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": image},\n",
    "        shuffle=False)\n",
    "    pred_results = list(classifier.predict(input_fn=pred_input_fn))\n",
    "    return [p['classes'] for p in pred_results],[p['probabilities'] for p in pred_results]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functions for creating dummy data to practice with\n",
    "def data(num_samps,w1,w2):\n",
    "    x=np.random.randn(num_samps,100)\n",
    "    return x, get_y(x,w1,w2)\n",
    "    \n",
    "def get_y(x,w1,w2):\n",
    "    y=np.exp(w1*x.T).T @ w2\n",
    "    return y\n",
    "    \n",
    "def make_image(sample):\n",
    "    height=[0]\n",
    "    for i in sample:\n",
    "        height.append(int(height[-1]+10*i))\n",
    "    height=np.array(height)-min(height)\n",
    "    height=(100*height/max(height)).astype('int')\n",
    "    rows=max(height)\n",
    "    image=np.zeros((rows,len(sample)))\n",
    "    for i in range(len(height)-1):\n",
    "        top=max(height[i-1],height[i])\n",
    "        bot=min(height[i-1],height[i])\n",
    "        image[bot:top,i]=1\n",
    "    return image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
