{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will need some of these packages at varoius points\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy import ndimage\n",
    "import tensorflow as tf\n",
    "\n",
    "\"\"\"\n",
    "This code processes images of handwritten letters and creates a CNN to classify these images\n",
    "We include every lower case letter as well as select upper case letters\n",
    "In addition the model will be trained to recognize various types of images that are not letters such as empty images, and images that only have straight lines\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def model(features,labels,mode):\n",
    "    #this function defines a custom model\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 100, 100, 1])#100x100\n",
    "    #perform convolutions with relu at the end of each convolution and some dropout, then pooling\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=64,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      use_bias=False)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)#50x50\n",
    "    dropoutp1=tf.layers.dropout(inputs=pool1,rate=0.05,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=dropoutp1,\n",
    "      filters=32,\n",
    "      kernel_size=[3, 3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      use_bias=False)\n",
    "  \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)#25x25\n",
    "    dropoutp2=tf.layers.dropout(inputs=pool2,rate=0.06,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv3 = tf.layers.conv2d(\n",
    "      inputs=dropoutp2,\n",
    "      filters=24,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      use_bias=False)\n",
    "      \n",
    "    pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[5,5], strides=5)#5x5\n",
    "    dropoutp3=tf.layers.dropout(inputs=pool3,rate=0.07,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    \n",
    "    conv4 = tf.layers.conv2d(\n",
    "      inputs=dropoutp3,\n",
    "      filters=16,\n",
    "      kernel_size=[3,3],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu,\n",
    "      use_bias=False)\n",
    "    \n",
    "    #flatten the images which are 5x5 but is also 16 units deep (because our last convolution layer had 16 filters) to give total length of 3*3*81\n",
    "    pool4_flat=tf.reshape(conv4, [-1,16*25])\n",
    "    #define our dense layer\n",
    "    dense=tf.layers.dense(inputs=pool4_flat,units=256,activation=tf.nn.elu)\n",
    "    #do one final dropout, this time much more dropout than we saw earlier\n",
    "    dropout=tf.layers.dropout(inputs=dense,rate=0.4,training=mode==tf.estimator.ModeKeys.TRAIN)\n",
    "    logits=tf.layers.dense(inputs=dropout,units=3)\n",
    "    \n",
    "    predictions={\n",
    "      \"classes\":tf.argmax(input=logits,axis=1),\n",
    "      \"probabilities\":tf.nn.softmax(logits,name=\"softmax_tensor\")\n",
    "      }\n",
    "    \n",
    "    #perform the operations appropriate for the mode we are in\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,predictions=predictions)\n",
    "    \n",
    "    labels_one_hot=tf.one_hot(indices=tf.cast(labels, tf.int32), depth=3)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=labels_one_hot, logits=logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer=tf.train.GradientDescentOptimizer(learning_rate=.01)\n",
    "        train_op = optimizer.minimize(\n",
    "          loss=loss,\n",
    "          global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        eval_metric_ops = {\n",
    "          \"accuracy\": tf.metrics.accuracy(\n",
    "                                  labels,\n",
    "                                  predictions[\"classes\"])}\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "        \n",
    "def get_feature_dict(images,labes):\n",
    "    #simply makes a dictionary mapping input (x's) to correct output (y's)\n",
    "    return {\"x\":images,\"y\":labels}\n",
    "        \n",
    "def train(train_data,train_labels,eval_data,eval_labels,model_folder,batch_size,steps):\n",
    "    #we take a a folder with images to train on\n",
    "    #a folder to evaluate our model with\n",
    "    #and a folder to save our model in, if this folder already has a model it will attempt to restore that model\n",
    "    #Raises an error if the model folder contains a model that does not match the format defined in our model function\n",
    "\n",
    "    classifier = tf.estimator.Estimator(model_fn = model, model_dir = model_folder)\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=20)\n",
    "    #we can see the above log results for every 50 steps during training\n",
    "    #Train the model\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": train_data},\n",
    "        y=train_labels,\n",
    "        batch_size=batch_size,\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    classifier.train(\n",
    "        input_fn=train_input_fn,\n",
    "        steps=steps,\n",
    "        hooks=[logging_hook])\n",
    "    \n",
    "    eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": eval_data},\n",
    "        y=eval_labels,\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    eval_results = classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print(eval_results)\n",
    "    \n",
    "def predict(image,model_folder):\n",
    "    #this model takes an image and a folder with a trained model and makes a prediction using the model\n",
    "    classifier= tf.estimator.Estimator(model_fn = model, model_dir = model_folder)\n",
    "    tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "    logging_hook = tf.train.LoggingTensorHook(\n",
    "        tensors=tensors_to_log, every_n_iter=100)\n",
    "\n",
    "    # predict with the model and print results\n",
    "    pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\": image},\n",
    "        shuffle=False)\n",
    "    pred_results = list(classifier.predict(input_fn=pred_input_fn))\n",
    "    return [p['classes'] for p in pred_results],[p['probabilities'] for p in pred_results]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data(num_samps,w1,w2):\n",
    "    x=np.random.randn(num_samps,100)\n",
    "    return x, get_y(x,w1,w2)\n",
    "    \n",
    "def get_y(x,w1,w2):\n",
    "    y=np.exp(w1*x.T).T @ w2\n",
    "    return y\n",
    "    \n",
    "def make_image(sample):\n",
    "    height=[0]\n",
    "    for i in sample:\n",
    "        height.append(int(height[-1]+10*i))\n",
    "    height=np.array(height)-min(height)\n",
    "    height=(100*height/max(height)).astype('int')\n",
    "    rows=max(height)\n",
    "    image=np.zeros((rows,len(sample)))\n",
    "    for i in range(len(height)-1):\n",
    "        top=max(height[i-1],height[i])\n",
    "        bot=min(height[i-1],height[i])\n",
    "        image[bot:top,i]=1\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1=np.random.randn(100,1)/1.6\n",
    "w2=np.random.randn(100)/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1,w2=np.random.randn(100,1)*.1,np.random.randn(100)*2\n",
    "x,y=data(20000,w1,w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8495575826603865"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imx=np.array([make_image(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.629601612048589"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.925089758079634"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7331150715312501"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_y=[]\n",
    "for i in y:\n",
    "    if i<-1:\n",
    "        lab_y.append(0)\n",
    "    elif i>.75:\n",
    "        lab_y.append(2)\n",
    "    else:\n",
    "        lab_y.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_y=np.array(lab_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 0, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 0, 1, 2, 0, 2, 2, 2, 0,\n",
       "       2, 2, 2, 1, 2, 1, 0, 0, 2, 2, 1, 0, 1, 1, 2, 2, 2, 2, 2, 2, 0, 1,\n",
       "       0, 2, 1, 1, 1, 0, 2, 2, 1, 0, 1, 2, 1, 1, 0, 2, 1, 2, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 2,\n",
       "       1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_y[:90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f12da56cc50>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-0\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1126803159713745, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.101672649383545.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-10-23:58:37\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-11-00:00:50\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.50525, global_step = 100, loss = 1.0329149\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: model/model.ckpt-100\n",
      "{'accuracy': 0.50525, 'loss': 1.0329149, 'global_step': 100}\n"
     ]
    }
   ],
   "source": [
    "train(imx[:8000],lab_y[:8000],imx[8000:],lab_y[8000:],'model/',25,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f125e5a1e48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 100 into model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.31721011 0.24178615 0.44100374]\n",
      " [0.24103598 0.27476528 0.48419874]\n",
      " [0.2650608  0.28051256 0.45442664]\n",
      " [0.2419242  0.27010997 0.48796583]\n",
      " [0.22056417 0.31959498 0.45984085]\n",
      " [0.23178583 0.24492103 0.52329314]\n",
      " [0.21980048 0.26681613 0.51338339]\n",
      " [0.23877968 0.29469401 0.46652631]\n",
      " [0.2250661  0.35996926 0.41496464]\n",
      " [0.18167192 0.34932958 0.46899849]\n",
      " [0.228534   0.34408797 0.42737803]\n",
      " [0.23938138 0.35728809 0.40333052]\n",
      " [0.23014095 0.26399803 0.50586102]\n",
      " [0.28778367 0.26333511 0.44888122]\n",
      " [0.22023019 0.29975218 0.48001762]\n",
      " [0.20560951 0.2991701  0.49522039]\n",
      " [0.24918774 0.33769543 0.41311684]\n",
      " [0.21629835 0.26522495 0.51847671]\n",
      " [0.25061204 0.26421243 0.48517553]\n",
      " [0.20235045 0.28784961 0.50979994]\n",
      " [0.19885795 0.2950791  0.50606295]\n",
      " [0.22059189 0.26065997 0.51874815]\n",
      " [0.23872457 0.33231429 0.42896114]\n",
      " [0.19977567 0.25938636 0.54083797]\n",
      " [0.25315982 0.331924   0.41491618]]\n",
      "INFO:tensorflow:loss = 0.9128676652908325, step = 101\n",
      "INFO:tensorflow:probabilities = [[0.21816791 0.29106662 0.49076547]\n",
      " [0.21312729 0.30818801 0.4786847 ]\n",
      " [0.2876204  0.31197246 0.40040714]\n",
      " [0.24786168 0.28490715 0.46723117]\n",
      " [0.24488444 0.32709897 0.42801659]\n",
      " [0.19198509 0.32034478 0.48767013]\n",
      " [0.2235981  0.2353845  0.54101741]\n",
      " [0.27849926 0.24556973 0.47593101]\n",
      " [0.22343334 0.30711051 0.46945615]\n",
      " [0.2387038  0.2862796  0.47501659]\n",
      " [0.24238267 0.24475076 0.51286657]\n",
      " [0.24032472 0.30913615 0.45053913]\n",
      " [0.26209237 0.32895848 0.40894915]\n",
      " [0.24196728 0.28690228 0.47113043]\n",
      " [0.21293264 0.31444857 0.4726188 ]\n",
      " [0.26356573 0.23212504 0.50430923]\n",
      " [0.25387286 0.31648803 0.4296391 ]\n",
      " [0.23930865 0.30374435 0.456947  ]\n",
      " [0.24412315 0.29708811 0.45878874]\n",
      " [0.17764332 0.30926199 0.51309468]\n",
      " [0.27023219 0.32167271 0.4080951 ]\n",
      " [0.26439758 0.2684852  0.46711722]\n",
      " [0.20353259 0.33015683 0.46631058]\n",
      " [0.23115501 0.25778735 0.51105764]\n",
      " [0.25805758 0.32037913 0.42156329]] (15.599 sec)\n",
      "INFO:tensorflow:probabilities = [[0.20616557 0.33719294 0.45664148]\n",
      " [0.19490384 0.25350819 0.55158797]\n",
      " [0.24515011 0.25473399 0.5001159 ]\n",
      " [0.26615589 0.26208574 0.47175837]\n",
      " [0.21357689 0.32080075 0.46562236]\n",
      " [0.20211123 0.34914153 0.44874723]\n",
      " [0.20645307 0.27714114 0.51640578]\n",
      " [0.19111894 0.2727047  0.53617636]\n",
      " [0.27322455 0.33506448 0.39171097]\n",
      " [0.18400059 0.2768348  0.53916461]\n",
      " [0.23373329 0.27098115 0.49528556]\n",
      " [0.27839374 0.2976746  0.42393166]\n",
      " [0.20120206 0.30988314 0.4889148 ]\n",
      " [0.24574853 0.26154878 0.49270269]\n",
      " [0.20352744 0.27082072 0.52565184]\n",
      " [0.22664948 0.32110527 0.45224524]\n",
      " [0.2434513  0.28665082 0.46989788]\n",
      " [0.22289222 0.32430087 0.45280691]\n",
      " [0.21775226 0.32011445 0.46213329]\n",
      " [0.22312983 0.26537101 0.51149917]\n",
      " [0.2854848  0.26646714 0.44804806]\n",
      " [0.27618975 0.28156693 0.44224332]\n",
      " [0.21972741 0.30976672 0.47050587]\n",
      " [0.23445286 0.28548373 0.48006341]\n",
      " [0.20438512 0.24608177 0.54953311]] (15.698 sec)\n",
      "INFO:tensorflow:probabilities = [[0.19605889 0.26979506 0.53414604]\n",
      " [0.24217435 0.23668177 0.52114388]\n",
      " [0.18199661 0.2746297  0.54337369]\n",
      " [0.15689123 0.26308092 0.58002785]\n",
      " [0.22231223 0.25654097 0.5211468 ]\n",
      " [0.21595317 0.2967675  0.48727932]\n",
      " [0.21590185 0.30779036 0.4763078 ]\n",
      " [0.18031962 0.34521314 0.47446724]\n",
      " [0.25292771 0.28673431 0.46033799]\n",
      " [0.19811203 0.32464102 0.47724695]\n",
      " [0.22044983 0.27819685 0.50135333]\n",
      " [0.21268351 0.32664974 0.46066675]\n",
      " [0.17108079 0.32703899 0.50188022]\n",
      " [0.216548   0.34030735 0.44314465]\n",
      " [0.21100847 0.33849944 0.45049209]\n",
      " [0.23530363 0.28741266 0.47728371]\n",
      " [0.17819214 0.27825251 0.54355535]\n",
      " [0.20867125 0.28378717 0.50754158]\n",
      " [0.21495121 0.29516424 0.48988454]\n",
      " [0.20965734 0.35556046 0.4347822 ]\n",
      " [0.23505579 0.30514431 0.4597999 ]\n",
      " [0.19775858 0.27155414 0.53068728]\n",
      " [0.18354839 0.36285302 0.45359859]\n",
      " [0.20659781 0.26041703 0.53298516]\n",
      " [0.21562916 0.29454782 0.48982302]] (15.408 sec)\n",
      "INFO:tensorflow:probabilities = [[0.21633491 0.37836182 0.40530327]\n",
      " [0.14615257 0.25669762 0.59714981]\n",
      " [0.20081379 0.29058106 0.50860515]\n",
      " [0.22165316 0.30788729 0.47045955]\n",
      " [0.17056666 0.34444857 0.48498477]\n",
      " [0.22511692 0.27491803 0.49996505]\n",
      " [0.16708021 0.24580746 0.58711232]\n",
      " [0.20371841 0.32180906 0.47447253]\n",
      " [0.18746829 0.26274915 0.54978256]\n",
      " [0.27356585 0.29663626 0.42979788]\n",
      " [0.20639731 0.26111704 0.53248564]\n",
      " [0.21205836 0.26996969 0.51797195]\n",
      " [0.20080653 0.34009762 0.45909585]\n",
      " [0.23086593 0.33359151 0.43554256]\n",
      " [0.21976003 0.32048517 0.4597548 ]\n",
      " [0.22335485 0.33855165 0.4380935 ]\n",
      " [0.23657713 0.26218354 0.50123933]\n",
      " [0.17801373 0.35700973 0.46497654]\n",
      " [0.24165019 0.34436926 0.41398054]\n",
      " [0.23195932 0.29360144 0.47443925]\n",
      " [0.19043675 0.25740533 0.55215792]\n",
      " [0.23573291 0.27912178 0.4851453 ]\n",
      " [0.20618395 0.284336   0.50948006]\n",
      " [0.22252055 0.32188884 0.45559061]\n",
      " [0.21244604 0.32626302 0.46129094]] (15.692 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.1224550008773804.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-11-00:02:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-200\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-11-00:04:51\n",
      "INFO:tensorflow:Saving dict for global step 200: accuracy = 0.50525, global_step = 200, loss = 1.030835\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: model/model.ckpt-200\n",
      "{'accuracy': 0.50525, 'loss': 1.030835, 'global_step': 200}\n"
     ]
    }
   ],
   "source": [
    "train(imx[:8000],lab_y[:8000],imx[8000:],lab_y[8000:],'model/',25,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
